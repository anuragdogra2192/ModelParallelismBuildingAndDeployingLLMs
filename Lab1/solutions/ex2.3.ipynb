{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /dli/code/pretrain_gpt_2GPU.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# Distributed training args\n",
    "NNODES=1\n",
    "GPUS_PER_NODE=2         # <--- CHANGED HERE\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1\n",
    "\n",
    "# Distributed training \n",
    "MICRO_BATCH_SIZE=16\n",
    "GLOBAL_BATCH_SIZE=32    # <--- CHANGED HERE\n",
    "\n",
    "# Model architecture \n",
    "NLAYERS=12\n",
    "NHIDDEN=768\n",
    "NHEADS=32\n",
    "SEQ_LEN=1024\n",
    "\n",
    "# Data Paths\n",
    "VOCAB_FILE=/dli/data/GPT-2_assets/gpt2-vocab.json\n",
    "MERGE_FILE=/dli/data/GPT-2_assets/gpt2-merges.txt\n",
    "DATA_PATH=[1.0,/dli/data/GPT-2_assets/my-gpt2_text_document]\n",
    "\n",
    "OUTPUT_PATH=/dli/nemo\n",
    "LOGS_PATH=/dli/nemo/logs\n",
    "NAME=\"1Node2GPUS\"      \n",
    "\n",
    "\n",
    "OPTIMIZER_ARGS=\" \\\n",
    "            model.optim.name=fused_adam \\\n",
    "            model.optim.betas=[0.9,0.95] \\\n",
    "            model.optim.lr=6e-5 \\\n",
    "            model.optim.sched.min_lr=6e-6 \\\n",
    "            model.optim.sched.name=CosineAnnealing \\\n",
    "            +model.optim.sched.max_steps=800 \\\n",
    "            model.optim.sched.warmup_steps=80 \\\n",
    "            model.optim.weight_decay=1e-1 \\\n",
    "        \"\n",
    "        \n",
    "TRAINER_ARGS=\" \\\n",
    "            trainer.gradient_clip_val=1.0 \\\n",
    "            trainer.precision=32 \\\n",
    "            trainer.devices=$GPUS_PER_NODE \\\n",
    "            trainer.num_nodes=$NNODES \\\n",
    "            trainer.max_steps=100 \\\n",
    "            trainer.enable_model_summary=true \\\n",
    "            trainer.log_every_n_steps=10 \\\n",
    "            trainer.val_check_interval=20 \\\n",
    "            trainer.limit_val_batches=10 \\\n",
    "        \"\n",
    "\n",
    "GPT_ARGS=\" \\\n",
    "            model.num_layers=$NLAYERS \\\n",
    "            model.hidden_size=$NHIDDEN \\\n",
    "            model.num_attention_heads=$NHEADS \\\n",
    "            model.encoder_seq_length=$SEQ_LEN \\\n",
    "            model.data.seq_length=$SEQ_LEN \\\n",
    "            model.max_position_embeddings=$SEQ_LEN \\\n",
    "            model.micro_batch_size=$MICRO_BATCH_SIZE \\\n",
    "            model.global_batch_size=$GLOBAL_BATCH_SIZE \\\n",
    "            model.tokenizer.vocab_file=$VOCAB_FILE \\\n",
    "            model.tokenizer.merge_file=$MERGE_FILE \\\n",
    "            model.init_method_std=0.006 \\\n",
    "            $OPTIMIZER_ARGS \\\n",
    "        \"\n",
    "\n",
    "OUTPUT_ARGS=\" \\\n",
    "            exp_manager.explicit_log_dir=$OUTPUT_PATH/$NAME \\\n",
    "            exp_manager.resume_if_exists=false \\\n",
    "            exp_manager.name=$NAME \\\n",
    "        \"\n",
    "\n",
    "PARALLEL_ARGS=\" \\\n",
    "            model.tensor_model_parallel_size=$TP_SIZE \\\n",
    "            model.pipeline_model_parallel_size=$PP_SIZE \\\n",
    "        \"\n",
    "\n",
    "\n",
    "export CMD=\" \\\n",
    "            python /dli/code/NeMo/examples/nlp/language_modeling/megatron_gpt_pretraining.py \\\n",
    "            --config-path=/dli/code/NeMo/examples/nlp/language_modeling/conf/ \\\n",
    "            --config-name=megatron_gpt_config.yaml \\\n",
    "            $TRAINER_ARGS \\\n",
    "            $PARALLEL_ARGS \\\n",
    "            $GPT_ARGS \\\n",
    "            $OUTPUT_ARGS \\\n",
    "            model.data.data_prefix=$DATA_PATH \\\n",
    "            model.data.data_impl=mmap \\\n",
    "            model.data.splits_string=\\\"949,50,1\\\" \\\n",
    "        \"\n",
    "\n",
    "bash -c '$LAUNCHER $CMD' 2>&1 | tee -a $LOGS_PATH/$NAME.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
